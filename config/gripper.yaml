# Robot parameters
robot:
  model_path: assets/gripper/wsg50_one_motor_gripper_new.sdf
  max_translation: 0.03
  max_yaw_rotation: 0.15
  max_force: 100
  #discrete: False
  #step_size: 0.01 #For discrete action space
  #yaw_step: 0.1
  num_actions_pad: 2
  include_robot_height: True


# Experimental setup parameters
scene:
  scene_type: WithBody # OnTable scene is easier for the table clearing task
  #scene_type: "OnFloor"
  data_set: random_urdfs

# Simulation parameters
simulation:
  real_time: False
  visualize: True
  
sensor:
  camera_info: config/camera_info.yaml
  transform: config/camera_transform.yaml
  encoder_dir: config/encoder.yaml
  encode: True
  visualize: True

  # Randomize camera parameters
  randomize:
    focal_length: 4
    optical_center: 2
    translation: 0.002
    rotation: 0.0349

# Custom shaped reward function parameters
reward:
  custom: True
  shaped: True
  terminal_reward: 5_000_000.
  # lift_success: 1000.
  grasp_reward: 100_000.
  delta_z_scale: 100.
  close_penalty: 1000.
  out_penalty: 1000.
  time_penalty: 10.
  table_clearing: False # False - picks only one item. With True the episode terminates after each objects are cleared. Table clearing works better with the curriculum parameter max object [1, 5] 

# Generate new initial states until at least on object is within the FOV
skip_empty_initial_state: True

# Use simplified problem formulation
simplified: False
# Depth + Actuator
observation: Full
# RGB + Depth + Actuator
full_observation: True
# Markov decision process parameters
discount_factor: 0.99
time_horizon: 300
# normalize the input and rewards
normalize: True

DDPG:
  batch_size: 32
  tau: 0.1
  gamma: 0.99
  epsilon_start: 5
  epsilon_end: 0
  epsilon_decay: 200

SAC:
  max_iters: 10
  batch_size: 32
  layers: [64, 64]
  buffer_size: 10000
  step_size: 0.000001
  total_timesteps: 1_000_000